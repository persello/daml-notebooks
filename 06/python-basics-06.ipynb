{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General instructions\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel/runtime** (Colab: in the menubar, select *Runtime*$\\rightarrow$*Factory Reset Runtime*; Jupyter: in the menubar, select *Kernel*$\\rightarrow$*Restart*) and then **run all cells** (Colab: in the menubar, select *Runtime*$\\rightarrow$*Run all*; Jupyter: in the menubar, select *Cell*$\\rightarrow$*Run All*).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `\"YOUR ANSWER HERE\"`, as well as the list of the group members in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter here the *Group Name* and the list of *Group Members*.\n",
    "\n",
    "`GROUP NAME`\n",
    "\n",
    "`GROUP MEMBERS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to have an evaluation DO NOT delete/cut the cells with code and answers. Once you have finished you can downolad the notebook (Colab: in the menubar, select *File*$\\rightarrow$*Download .ipynb*; Jupyter: in the menubar, select *File*$\\rightarrow$*Download as*$\\rightarrow$*Notebook (.ipynb)*) and upload as an assignment on the e-learning platform.\n",
    "\n",
    "The following cell will load the Google Drive extension for the current notebook, when the variable `MOUNT` is `True`. This allow you to mount the Google Drive filesystem for file persistence. The mountpoint will be `/content/gdrive`.\n",
    "Furthermore, it will set the `PATH` variable, from now on, so that if you have to refer to external files you could do that by writing:\n",
    "\n",
    "```python\n",
    "os.path.join(PATH, filename)\n",
    "```\n",
    "\n",
    "This will append the filename after the specific PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MOUNT = False\n",
    "if 'google.colab' in str(get_ipython()) and MOUNT:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    PATH = '/content/gdrive/MyDrive'\n",
    "else:\n",
    "    PATH = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important warning\n",
    "\n",
    "**⚠️ avoid copying, removing or modifying test cells, if you do that your assignment might be graded wrongly ⚠️**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map/Reduce *advanced* simulator\n",
    "\n",
    "The library `map_reduce.py` provides a simulator of the *map/reduce* paradigm, which simulates the *map/reduce* steps by performing them in parallel.\n",
    "\n",
    "You can give a look at the file content, if you're interested in the implementation.\n",
    "\n",
    "The `map_reduce` module can be loaded by issuing the command:\n",
    "\n",
    "```python\n",
    "from map_reduce import map_reduce\n",
    "```\n",
    "\n",
    "provided that the `map_reduce.py` is in **the same** directory as this notebook (or the notebook using it). It is not a systemwide library but a custom one.\n",
    "\n",
    "The `map_reduce` module is a higher-order function that takes two functions as its arguments, namely the `mapper` and the `reducer`, and returns another function (call it `apply`) that has an iterable as its argument. The `apply` function will perform all the steps of the *map/reduce* pipeline, namely:\n",
    "\n",
    "1. it will transform each item of the input iterable (in parallel) by applying the `mapper()` function to that item;\n",
    "2. it will partition the results of the *map* application into blocks having the same key value;\n",
    "3. it will send each block to a single `reducer()` function that performs the reduction in parallel.\n",
    "\n",
    "You will see an example of adapting the map/reduce functions for counting words and an usage of the map reduce simulator in the following cells. The final output format is slightly different from the one above and is more similar to an actual output of a map/reduce pipeline (i.e., a list of tuples instead of a dictionary).\n",
    "\n",
    "The signatures of the two functions is as follows:\n",
    "\n",
    "* `mapper(item) -> list of tuples (k, v)`\n",
    "* `reducer(k, list of values) -> list of any`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8860c5771806098f10e71d42772f167",
     "grade": false,
     "grade_id": "cell-6f4a84fbf9a0d071",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This will install the typeguard library that performs runtime checking of the function times\n",
    "# it's needed in colab because every time you restart it a new environment will be created\n",
    "!pip3 install typeguard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8d6caa87fa2d7daf61e8cf4a00a17f1",
     "grade": false,
     "grade_id": "cell-b6967f782e4f8c0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "We aim at determining the top-$k$ salaries of a company. The employee data is stored in multiple files, one for each department, and has the following format:\n",
    "\n",
    "```\n",
    "<first_name>;<last_name>;<salary>\n",
    "```\n",
    "\n",
    "Since the company is really big, we cannot store in memory the full dataset consisting of all the files and we have to resort to the *map/reduce* paradigm to compute those values company-wide, that is to find the top-$k$ salaries among the *whole* company.\n",
    "\n",
    "A possible modeling of the problem in terms of the Map/Reduce paradigm is to provide each mapper with the name of a single file and let it read its content and compute the top-$k$ salaries of that file.\n",
    "\n",
    "As for the reducer, instead, we aim at having just a single reducer (*how can you ensure that a single reducer will be used?*) that selects among the list of top-$k$s that were determined by each mapper.\n",
    "\n",
    "```\n",
    "data_00.txt -----> mapper(): top-k of data_00.txt  ------+\n",
    "                                                          \\\n",
    "data_01.txt -----> mapper(): top-k of data_01.txt  --------+---> reducer : determines the top-k out of the top-ks\n",
    "                                                          /\n",
    "                                            ...          /\n",
    "                                                        /\n",
    "data_n-1.txt -----> mapper(): top-k of data_n-1.txt ---+\n",
    "```\n",
    "\n",
    "Write the mapper and the reducer function to this aim.\n",
    "\n",
    "We want to have the result in form of the top-$k$ tuples, that is having also the names of the overall top-$k$ employees. Assume that $k$ is set, initially, as a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c100ce9c72ae323b09aaf4871a1ccba1",
     "grade": true,
     "grade_id": "cell-97131aec57d655e8",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from map_reduce import map_reduce\n",
    "\n",
    "k = 5\n",
    "\n",
    "def mapper(filename):\n",
    "    # process the file in order to extract the employees having the top k salaries\n",
    "    # you should ensure that the output goes to the same reducer\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def reducer(key, top_k_items):\n",
    "    # process the list of top k items to extract the top k out of the top k\n",
    "    # you might check what's coming from the partitioner by means of print(top_k_items)\n",
    "    # and process it in the correct way\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6e44d865d1d5476c21d7192067e06a2",
     "grade": true,
     "grade_id": "cell-2ec5972c3ff03bb4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# the glob library allows to search for files using the OS wildcards in a given directory, that is it creates\n",
    "# an iterator of all filenames whose pattern is specified\n",
    "\n",
    "import glob\n",
    "\n",
    "apply = map_reduce(mapper, reducer)\n",
    "\n",
    "result = apply(glob.glob('data_*.txt'))\n",
    "\n",
    "print(result)\n",
    "\n",
    "# this is the check against the sequential algorithm\n",
    "\n",
    "def process_line(l):\n",
    "    l = l.strip().split(';')\n",
    "    l[2] = float(l[2])\n",
    "    return tuple(l)\n",
    "\n",
    "top_k = []\n",
    "for filename in glob.glob('data_*.txt'):\n",
    "    with open(filename) as f:\n",
    "        data = sorted(map(process_line, f), key=lambda t: -t[2])\n",
    "    top_k += data[:k]\n",
    "top_k = sorted(top_k, key=lambda t: -t[2])\n",
    "assert top_k[:k] == result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c54a4f11b89d42177ef17336c409f264",
     "grade": false,
     "grade_id": "cell-fbb3ef0da3c52340",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "We want to generalize the mapper / reducer to be able to work with different values of $k$.\n",
    "\n",
    "To this aim we want to make use of functional programming tools and:\n",
    "\n",
    "1. add an argument `k` to the mapper and the reducer;\n",
    "2. encapsulate the creation and application of the `apply` function in a function `compute_top(k)` that wraps the whole computation and returns the results of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f89ca0a3c6e0bbca7b947cbeb25cf0ee",
     "grade": true,
     "grade_id": "cell-bf155230c48f8c8f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def compute_top_k(k):\n",
    "    # the solution should use the partial binding\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "apply = compute_top_k(5)\n",
    "result = apply(glob.glob('data_*.txt'))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
